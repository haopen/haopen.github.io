<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.31" />


<title>中文文本处理简要介绍 z - 彭浩 ~ Hao Peng</title>
<meta property="og:title" content="中文文本处理简要介绍 z - 彭浩 ~ Hao Peng">



  








<link href='//cdn.bootcss.com/highlight.js/9.11.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">

<link rel="stylesheet" href="/css/custom.css">

<link rel="stylesheet" href="/css/localsearch.css">

<link rel="stylesheet" href="/lib/lightGallery/css/lightgallery.css">

<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script async src="/js/load-typekit.js"></script>



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="Hao Peng">
  </a>

  <ul class="nav-links">
    
	
	
    
	

	
    
    <li class=""><a href="/">首页</a></li>
    
    <li class=""><a href="/data/">归档</a></li>
    
    <li class=""><a href="/data/categories/">分类</a></li>
    
    <li class=""><a href="/data/tags/">标签</a></li>
    
    <li class=""><a href="javascript:;" class="popup-trigger"><i class="fa fa-search" aria-hidden="true" title="搜索"></i></a></li>
    
  </ul>
</nav>


<div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocapitalize="off" autocomplete="off" autocorrect="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>
      </header>


<main class="content" role="main">

  <article class="article">
    

    
<h1 class="article-title">中文文本处理简要介绍 z


</h1>



<div class="article-date">
  <span> 李绳 ·   2016/01/07</span>
  <span class="article-toolbar">
    
    <a href="/data/index.xml" type="application/rss+xml" target="_blank"><i class="fa fa-rss" aria-hidden="true" title="RSS feed"></i></a>
    
    <a href="https://twitter.com/home?status=%E4%B8%AD%E6%96%87%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E7%AE%80%E8%A6%81%E4%BB%8B%E7%BB%8D&#43;z&#43;%2Fdata%2F2016%2F01%2F07%2Fintro-to-chinese-nlp%2F&#43;via&#43;%40haopeng" target="_blank"><i class="fa fa-twitter" aria-hidden="true" title="Share via Twitter"></i></a>
    <a href="http://service.weibo.com/share/share.php?content=utf-8&amp;title=%E4%B8%AD%E6%96%87%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E7%AE%80%E8%A6%81%E4%BB%8B%E7%BB%8D&#43;z&#43;%40%E5%BD%AD%E6%B5%A9&amp;url=%2Fdata%2F2016%2F01%2F07%2Fintro-to-chinese-nlp%2F" target="_blank"><i class="fa fa-weibo" aria-hidden="true" title="分享到新浪微博"></i></a>
    <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><i class="fa fa-cc" aria-hidden="true" title="Attribution-NonCommercial-ShareAlike 4.0 International"></i></a>
    
	
    
	
    <a href="https://github.com/haopen/Blogdown/edit/master/content/data/2016-01-07-intro-to-chinese-nlp.md"><i class="fa fa-pencil-square-o" aria-hidden="true" title="Suggest an edit of this page"></i></a>
    
    </span>
</div>

<div class="article-taxonomies">
  
  <span class="category-prefix"><i class="fa fa-folder-o"></i></span>
  
  <span class="taxonomy-category"><a href="/categories/5-%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86" title="数据处理">数据处理</a></span>;
  
  
  
  <span class="tag-prefix"><i class="fa fa-tags"></i></span>
  
  <span class="taxonomy-tag"><a href="/tags/5-nlp" title="NLP">NLP</a></span>;
  
  <span class="taxonomy-tag"><a href="/tags/5-%E4%B8%AD%E6%96%87" title="中文">中文</a></span>;
  
  <span class="taxonomy-tag"><a href="/tags/5-%E5%88%86%E8%AF%8D" title="分词">分词</a></span>;
  
  <span class="taxonomy-tag"><a href="/tags/5-%E6%96%87%E6%9C%AC" title="文本">文本</a></span>;
  
  <span class="taxonomy-tag"><a href="/tags/5-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86" title="自然语言处理">自然语言处理</a></span>;
  
  <span class="taxonomy-tag"><a href="/tags/5-%E8%AF%8D%E5%90%91%E9%87%8F" title="词向量">词向量</a></span>;
  
  <span class="taxonomy-tag"><a href="/tags/5-%E8%AF%8D%E6%80%A7%E6%A0%87%E6%B3%A8" title="词性标注">词性标注</a></span>;
  
  
</div>


    
    <div class="article-content cn" id="articleContent">
      

<p><strong>原文地址</strong>：<a href="https://cosx.org/2016/01/intro-to-chinese-nlp/" target="_blank">https://cosx.org/2016/01/intro-to-chinese-nlp/</a></p>

<p>本文作者李绳，博客地址 <a href="http://acepor.github.io/" target="_blank">http://acepor.github.io/</a>。作者自述：</p>

<blockquote>
<p>一位文科生曾励志成为语言学家<br />出国后阴差阳错成了博士候选人<br />三年后交完论文对学术彻底失望<br />回国后误打误撞成了数据科学家</p>
</blockquote>

<p>作为一个处理自然语言数据的团队，我们在日常工作中要用到不同的工具来预处理中文文本，比如 <a href="https://github.com/fxsjy/jieba" target="_blank">Jieba</a> 和 <a href="http://nlp.stanford.edu/software/" target="_blank">Stanford NLP software</a>。出于准确性和效率的考虑，我们选择了Stanford NLP software， 所以本文将介绍基于 Stanford NLP software 的中文文本预处理流程。</p>

<h1 id="中文文本处理简要介绍">中文文本处理简要介绍</h1>

<p>与拉丁语系的文本不同，中文并不使用空格作为词语间的分隔符。比如当我们说“We love coding.”，这句英文使用了两个空格来分割三个英文词汇；如果用中文做同样的表述， 就是“我们爱写代码。”，其中不包含任何空格。因而，处理中文数据时，我们需要进行分词，而这恰恰时中文自然语言处理的一大难点。</p>

<p>下文将介绍中文文本预处理的几个主要步骤：</p>

<ol>
<li>中文分词</li>
<li>标注词性</li>
<li>生成词向量</li>
<li>生成中文依存语法树</li>
</ol>

<h1 id="stanford-nlp-software-简要介绍">Stanford NLP software 简要介绍</h1>

<p>Stanford NLP software 是一个较大的工具合集：包括<a href="http://127.0.0.1:21142/rmd_output/2/nlp.stanford.edu/software/tagger.shtml" target="_blank">Stanford POS tagger</a>等组件，也有一个包含所有组件的合集<a href="http://127.0.0.1:21142/rmd_output/2/stanfordnlp.github.io/CoreNLP/" target="_blank">Stanford CoreNLP</a>。各个组件是由不同的开发者开发的，所以每一个工具都有自己的语法。当我们研究这些组件的文档时，遇到了不少问题。下文记录这些问题和相对应的对策，以免重蹈覆辙。</p>

<p>Stanford NLP 小组提供了一个简明的FAQ——<a href="http://nlp.stanford.edu/software/parser-faq.shtml" target="_blank">Stanford Parser FAQ</a> 和一份详细的Java文档 ——<a href="http://nlp.stanford.edu/nlp/javadoc/javanlp/overview-summary.html" target="_blank">Stanford JavaNLP API Documentation</a>。在这两份文档中，有几点格外重要：</p>

<blockquote>
<ul>
<li>尽管PSFG分词器小且快，Factored分词器更适用于中文，所以我们推荐使用后者。</li>
<li>中文分词器默认使用GB18030编码（Penn Chinese Treebank的默认编码）。</li>
<li>使用 <code>-encoding</code> 选项可以指定编码，比如 UTF-8，Big-5 或者 GB18030。</li>
</ul>
</blockquote>

<h1 id="中文预处理的主要步骤">中文预处理的主要步骤</h1>

<h2 id="1-中文分词">1. 中文分词</h2>

<p>诚如上面所言，分词是中文自然语言处理的一大难题。<a href="http://nlp.stanford.edu/software/segmenter.shtml" target="_blank">Stanford Word Segmenter</a> 是专门用来处理这一问题的工具。FAQ请参见 <a href="http://nlp.stanford.edu/software/segmenter-faq.shtml" target="_blank">Stanford Segmenter FAQ</a>。具体用法如下：</p>

<pre><code class="language-bash">bash -x segment.sh ctb INPUT_FILE UTF-8 0
</code></pre>

<p>其中 <code>ctb</code> 是词库选项，即 Chinese tree bank，也可选用 <code>pku</code>，即 Peking University。<code>UTF-8</code>是输入文本的编码，这个工具也支持 GB18030 编码。最后的0指定 n-best list 的大小，0表示只要最优结果。</p>

<h2 id="2-中文词性标注">2. 中文词性标注</h2>

<p>词性标注是中文处理的另一大难题。我们曾经使用过 Jieba 来解决这个问题，但效果不尽理想。Jieba 是基于词典规则来标注词性的，所以任意一个词在 Jieba 里有且只有一个词性。如果一个词有一个以上的词性，那么它的标签就变成了一个集合。比如“阅读”既可以表示动词，也可以理解为名词，Jieba 就会把它标注成 n（名词），而不是根据具体语境来给出合适的 v（动词）或 n（名词）的标签。这样一来，标注的效果就大打折扣。幸好 <a href="http://nlp.stanford.edu/software/tagger.shtml" target="_blank">Stanford POS Tagger</a> 提供了一个根据语境标注词性的方法。具体用法如下：</p>

<pre><code class="language-bash">java -mx3000m -cp &quot;./*&quot; edu.stanford.nlp.tagger.maxent.MaxentTagger -model models/chinese-distsim.tagger -textFile INPUT_FILE
</code></pre>

<ul>
<li><code>-mx3000m</code> 指定内存大小，可以根据自己的机器配置选择。</li>
<li><code>edu.stanford.nlp.tagger.maxent.MaxentTagger</code> 用于选择标注器，这里选用的是一个基于最大熵（Max Entropy）的标注器。</li>
<li><code>models/chinese-distsim.tagger</code> 用于选择分词模型。</li>
</ul>

<h2 id="3-生成词向量">3. 生成词向量</h2>

<p>深度学习是目前机器学习领域中最热门的一个分支。而生成一个优质的词向量是利用深度学习处理 NLP 问题的一个先决条件。除了 Google 的 <a href="https://code.google.com/p/word2vec/" target="_blank">Word2vec</a>，Stanford NLP 小组提供了另外一个选项——GLOVE。</p>

<p>使用Glove也比较简单，下载并解压之后，只要对里面的 <code>demo.sh</code> 脚本进行相应修改，然后执行这个脚本即可。</p>

<pre><code class="language-txt">CORPUS=text8                                    # 设置输入文件路径
VOCAB_FILE=vocab.txt                            # 设置输入词汇路径
COOCCURRENCE_FILE=cooccurrence.bin              
COOCCURRENCE_SHUF_FILE=cooccurrence.shuf.bin
BUILDDIR=build
SAVE_FILE=vectors                               # 设置输入文件路径
VERBOSE=2           
MEMORY=4.0                                      # 设置内存大小
VOCAB_MIN_COUNT=5                               # 设置词汇的最小频率
VECTOR_SIZE=50                                  # 设置矩阵维度
MAX_ITER=15                                     # 设置迭代次数
WINDOW_SIZE=15                                  # 设置词向量的窗口大小
BINARY=2
NUM_THREADS=8
X_MAX=10
</code></pre>

<h2 id="4-生成中文依存语法树">4. 生成中文依存语法树</h2>

<p>文本处理有时需要比词性更丰富的信息，比如句法信息，Stanford NLP 小组提供了两篇论文： <a href="http://nlp.stanford.edu/software/lex-parser.shtml" target="_blank">The Stanford Parser: A statistical parser</a> 和 <a href="http://nlp.stanford.edu/software/nndep.shtml" target="_blank">Neural Network Dependency Parser</a>，并在这两篇论文的基础上开发了两个工具，可惜效果都不太理想。前者的处理格式是正确的中文依存语法格式，但是速度极慢（差不多一秒一句）；而后者虽然处理速度较快，但生成的格式和论文 <a href="http://www.aclweb.org/anthology/W09-2307" target="_blank">Discriminative reordering with Chinese grammatical relations features – acepor</a>中的完全不一样。我们尝试了邮件联系论文作者和工具作者，并且在 <a href="https://stackoverflow.com/questions/33294148/how-to-use-nndep-parser-in-stanford-parser-to-process-chinese-data" target="_blank">Stackoverflow</a> 上提问，但这个问题似乎无解。</p>

<p>尽管如此，我们还是把两个方案都记录在此：</p>

<pre><code class="language-bash">java -cp &quot;*:.&quot; -Xmx4g edu.stanford.nlp.pipeline.StanfordCoreNLP -file INPUT_FILE -props StanfordCoreNLP-chinese.properties -outputFormat text -parse.originalDependencies
</code></pre>

<pre><code class="language-bash">java -cp &quot;./*&quot; edu.stanford.nlp.parser.nndep.DependencyParser -props nndep.props -textFile INPUT_FILE -outFile OUTPUT_FILE
</code></pre>

<h1 id="结论">结论</h1>

<p>预处理中文文本并非易事，Stanford NLP 小组对此作出了极大的贡献。我们的工作因而受益良多，所以我们非常感谢他们的努力。当然我们也期待 Stanford NLP software 能更上一层楼。</p>

<p>本文原载于 <a href="https://acepor.github.io/2015/12/17/General-Pipelines/" target="_blank">https://acepor.github.io/2015/12/17/General-Pipelines/</a>。</p>

    </div>
    

  </article>

  
<section id="comments">
  <div id="disqus_thread"></div>
  <script src="/js/disqusloader.min.js"></script>
  <script>
  var disqus_config = function () {
  
    this.page.url = "https:\/\/haopen.github.io\/" + location.pathname;
  
  };
  (function() {
    var inIFrame = function() {
      var iframe = true;
      try { iframe = window.self !== window.top; } catch (e) {}
      return iframe;
    };
    if (inIFrame()) return;
    var disqus_js = 'https://haopeng.disqus.com/embed.js';
    
    if (location.hash.match(/^#comment/)) {
      var d = document, s = d.createElement('script');
      s.src = disqus_js; s.async = true;
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    } else {
      disqusLoader('#disqus_thread', {
        scriptUrl: disqus_js, laziness: 0, disqusConfig: disqus_config
      });
    }
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>



</main>

      <footer class="footer">
        <ul class="footer-links">
          
          
          <li><a href="https://github.com/haopen"><i class="fa fa-github" aria-hidden="true" title="Github"></i><span class="sr-only">Github</span></a></li>
          <li><a href="https://twitter.com/haopeng"><i class="fa fa-twitter" aria-hidden="true" title="Twitter"></i><span class="sr-only">Twitter</span></a></li>
          <li><a href="http://weibo.com/seplost"><i class="fa fa-weibo" aria-hidden="true" title="新浪微博"></i><span class="sr-only">新浪微博</span></a></li>
          
          <li><a href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><i class="fa fa-cc" aria-hidden="true" title="Attribution-NonCommercial-ShareAlike 4.0 International"></i><span class="sr-only">Attribution-NonCommercial-ShareAlike 4.0 International</span></a></li>
          <li><a href="/"><i class="fa fa-copyright" aria-hidden="true" title="Copyright"></i> 2005 - 2017</a></li>
        </ul>
      </footer>
    </div>

	<div id="images-container"></div>

    <script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
	<script type="text/javascript" src="/lib/jquery/jquery.mousewheel.min.js"></script>
	<script type="text/javascript" src="/lib/lightGallery/js/lightgallery.min.js"></script>
	<script type="text/javascript" src="/lib/lightGallery/js/lg-thumbnail.min.js"></script>
	<script type="text/javascript" src="/lib/lightGallery/js/lg-fullscreen.min.js"></script>
	<script type="text/javascript" src="/lib/lightGallery/js/lg-zoom.min.js"></script>
	<script type="text/javascript" src="/js/lgGallery_Prepare.js"></script>
	<script type="text/javascript" src="/js/load-pangu.js"></script>
    
    <script async src="/js/center-img.js"></script>
    
    <script async src="/js/right-quote.js"></script>
    
    <script async src="/js/no-highlight.js"></script>
    
    <script async src="/js/fix-footnote.js"></script>
    
    <script async src="/js/local-search.js"></script>
    
    



<script src="//cdn.bootcss.com/highlight.js/9.11.0/highlight.min.js"></script>



<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/r.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/yaml.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/tex.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/matlab.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    

    
  </body>
</html>

