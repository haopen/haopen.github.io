<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.25" />


<title>谈谈 Bias-Variance Tradeoff z - 彭浩 ~ Hao Peng</title>
<meta property="og:title" content="谈谈 Bias-Variance Tradeoff z - 彭浩 ~ Hao Peng">



  








<link href='//cdn.bootcss.com/highlight.js/9.11.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">

<link rel="stylesheet" href="/css/custom.css">

<link rel="stylesheet" href="/css/localsearch.css">

<link rel="stylesheet" href="/lib/lightGallery/css/lightgallery.css">

<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script async src="/js/load-typekit.js"></script>



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="Hao Peng">
  </a>

  <ul class="nav-links">
    
	
	
    
	

	
    
    <li class=""><a href="/">首页</a></li>
    
    <li class=""><a href="/data/">归档</a></li>
    
    <li class=""><a href="/data/categories/">分类</a></li>
    
    <li class=""><a href="/data/tags/">标签</a></li>
    
    <li class=""><a href="javascript:;" class="popup-trigger"><i class="fa fa-search" aria-hidden="true" title="搜索"></i></a></li>
    
  </ul>
</nav>


<div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocapitalize="off" autocomplete="off" autocorrect="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>
      </header>


<main class="content" role="main">

  <article class="article">
    

    
<h1 class="article-title">谈谈 Bias-Variance Tradeoff z


</h1>



    
    <div class="article-content cn" id="articleContent">
      <p><strong>原文地址</strong>：<a href="http://liam0205.me/2017/03/25/bias-variance-tradeoff/" class="uri">http://liam0205.me/2017/03/25/bias-variance-tradeoff/</a></p>
<blockquote>
<p><strong>准确</strong>是两个概念。准是 <strong>bias</strong> 小，确是 <strong>variance</strong> 小。准确是相对概念，因为 bias-variance tradeoff。 ——Liam Huang</p>
</blockquote>
<p>在机器学习领域，人们总是希望使自己的模型尽可能准确地描述数据背后的真是规律。通俗所言的「准确」，其实就是误差小。在领域中，排除人为失误，人们一般会遇到三种误差来源：随机误差、偏差和方差。偏差和方差又与「欠拟合」及「过拟合」紧紧联系在一起。由于随机误差是不可消除的，所以此篇我们讨论在偏差和方差之间的权衡（Bias-Variance Tradeoff）。</p>
<!-- more -->
<div class="section level1">
<h1>定义</h1>
<div class="section level2">
<h2>数学上定义</h2>
<p>首先需要说明的是<strong>随机误差</strong>。随机误差是数据本身的噪音带来的，这种误差是不可避免的。一般认为随机误差服从高斯分布，记作 <span class="math inline">\(\epsilon\sim\mathcal N(0, \sigma_\epsilon)\)</span>。因此，若有变量 <span class="math inline">\(y\)</span> 作为预测值，以及 <span class="math inline">\(X\)</span> 作为自变量（协变量），那么我们将数据背后的真实规律 <span class="math inline">\(f\)</span> 记作</p>
<p><span class="math display">\[y = f(X) + \epsilon.\]</span></p>
<p>偏差和方差则需要在统计上做对应的定义。</p>
<ul>
<li><strong>偏差</strong>（bias）描述的是通过学习拟合出来的结果之期望，与真实规律之间的差距，记作 <span class="math inline">\(\text{Bias}(X) = E[\hat f(X)] - f(X)\)</span>。</li>
<li><strong>方差</strong>（variance）即是统计学中的定义，描述的是通过学习拟合出来的结果自身的不稳定性，记作 <span class="math inline">\(\text{Var}(X) = E\Bigl[\hat f(X) - E[\hat f(X)]\Bigr]\)</span>。</li>
</ul>
<p>以均方误差为例，有如下推论</p>
<span class="math display">\[\begin{equation}
\begin{aligned}
\text{Err}(X) &amp;= E\Bigl[\bigl(y - \hat f(X)\bigr)^2\Bigr] \\
              &amp;= E\Bigl[\bigl(f(X) + \epsilon - \hat f(X)\bigr)^2\Bigr] \\
              &amp;= \left(E[\hat{f}(X)]-f(X)\right)^2 + E\left[\left(\hat{f}(X)-E[\hat{f}(X)]\right)^2\right] +\sigma_\epsilon^2 \\
              &amp;= \text{Bias}^2 + \text{Variance} + \text{Random Error}.
\end{aligned}
\label{eq:err-comp}
\end{equation}\]</span>
</div>
<div class="section level2">
<h2>直观的图示</h2>
<p>下图将机器学习任务描述为一个「打靶」的活动：根据相同算法、不同数据集训练出的模型，对同一个样本进行预测；每个模型作出的预测相当于是一次打靶。</p>
<div class="figure">
<img src="/images/Data/BiasVariance/bias-and-variance.png" />

</div>
<p class="imgCaption">
<a href="http://scott.fortmann-roe.com/docs/BiasVariance.html" class="uri">http://scott.fortmann-roe.com/docs/BiasVariance.html</a>
</p>
<p>左上角的示例是理想状况：偏差和方差都非常小。如果有无穷的训练数据，以及完美的模型算法，我们是有办法达成这样的情况的。然而，现实中的工程问题，通常数据量是有限的，而模型也是不完美的。因此，这只是一个理想状况。</p>
<p>右上角的示例表示偏差小而方差大。靶纸上的落点都集中分布在红心周围，它们的期望落在红心之内，因此偏差较小。另外一方面，落点虽然集中在红心周围，但是比较分散，这是方差大的表现。</p>
<p>左下角的示例表示偏差大二方差小。显而易见，靶纸上的落点非常集中，说明方差小。但是落点集中的位置距离红心很远，这是偏差大的表现。</p>
<p>右下角的示例则是最糟糕的情况，偏差和方差都非常大。这是我们最不希望看到的结果。</p>
</div>
</div>
<div class="section level1">
<h1>举个栗子</h1>
<p>现在我们做一个模拟实验，用以说明至此介绍的内容。</p>
<p>首先，我们生成了两组 array，分别作为训练集和验证集。这里，<code>x</code> 与 <code>y</code> 是接近线性相关的，而在 <code>y</code> 上加入了随机噪声，用以模拟真实问题中的情况。</p>
<pre class="python"><code>import numpy as np
np.random.seed(42)  # the answer to life, the universe and everything
real = lambda x:x + x ** 0.1

x_train = np.linspace(0, 15, 100)
y_train = map(real, x_train)
y_noise = 2 * np.random.normal(size = x_train.size)
y_train = y_train + y_noise

x_valid = np.linspace(0, 15, 50)
y_valid = map(real, x_valid)
y_noise = 2 * np.random.normal(size = x_valid.size)
y_valid = y_valid + y_noise</code></pre>
<p>现在，我们选用最小平方误差作为损失函数，尝试用多项式函数去拟合这些数据。</p>
<pre class="python"><code>prop    = np.polyfit(x_train, y_train, 1)
prop_   = np.poly1d(prop)
overf   = np.polyfit(x_train, y_train, 15)
overf_  = np.poly1d(overf)</code></pre>
<p>这里，对于 <code>prop</code>，我们采用了一阶的多项式函数（线性模型）去拟合数据；对于 <code>overf</code>，我们采用了 15 阶的多项式函数（多项式模型）去拟合数据。如此，我们可以把拟合效果绘制成图。</p>
<pre class="python"><code>import matplotlib.pyplot as plt

_ = plt.figure(figsize = (14, 6))

plt.subplot(1, 2, 1)
prop_e  = np.mean((y_train - np.polyval(prop, x_train)) ** 2)
overf_e = np.mean((y_train - np.polyval(overf, x_train)) ** 2)
xp      = np.linspace(-2, 17, 200)
plt.plot(x_train, y_train, &#39;.&#39;)
plt.plot(xp, prop_(xp), &#39;-&#39;, label = &#39;proper, err: %.3f&#39; % (prop_e))
plt.plot(xp, overf_(xp), &#39;--&#39;, label = &#39;overfit, err: %.3f&#39; % (overf_e))
plt.ylim(-5, 20)
plt.legend()
plt.title(&#39;train set&#39;)

plt.subplot(1, 2, 2)
prop_e  = np.mean((y_valid - np.polyval(prop,  x_valid)) ** 2)
overf_e = np.mean((y_valid - np.polyval(overf, x_valid)) ** 2)
xp      = np.linspace(-2, 17, 200)
plt.plot(x_valid, y_valid, &#39;.&#39;)
plt.plot(xp, prop_(xp), &#39;-&#39;, label = &#39;proper, err: %.3f&#39; % (prop_e))
plt.plot(xp, overf_(xp), &#39;--&#39;, label = &#39;overfit, err: %.3f&#39; % (overf_e))
plt.ylim(-5, 20)
plt.legend()
plt.title(&#39;validation set&#39;)</code></pre>
<div class="figure">
<img src="/images/Data/BiasVariance/polyfit.png" alt="多项式拟合结果" />
<p class="caption">多项式拟合结果</p>
</div>
<p>以训练集上的结果来说，线性模型的误差要明显高于多项式模型。站在人类观察者的角度来说，这似乎是显而易见的：数据是围绕一个近似线性的函数附近抖动的，那么用简单的线性模型，自然就无法准确地拟合数据；但是，高阶的多项式函数可以进行各种「扭曲」，以便将训练集的数据拟合得更好。</p>
<p>这种情况，我们说线性模型在训练集上欠拟合（underfitting），并且它的偏差（bias）要高于多项式模型的偏差。</p>
<p>但这并不意味着线性模型在这个问题里，要弱于多项式模型。我们看到，在验证集上，线性模型的误差要小于多项式模型的误差。并且，线性模型在训练集和验证集上的误差相对接近，而多项式模型在两个数据集上的误差，差距就很大了。</p>
<p>这种情况，我们说多项式模型在训练集上过拟合（overfitting），并且它的方差（variance）要高于线性模型的偏差。此外，因为线性模型在两个集合上的误差较为接近，因此我们说线性模型在训练过程中未见的数据上，<strong>泛化能力</strong>更好。因为，在真实情况下，我们都需要使用有限的训练集去拟合模型，而后工作在无限的真实样本中，而这些真实样本对于模型训练过程都是不可见的。所以，模型的泛化能力，是非常重要的指标。</p>
<p>考虑到两个模型在验证集上的表现，在这个任务上，我们说<strong>线性模型</strong>表现得较好。</p>
</div>
<div class="section level1">
<h1>权衡之术</h1>
<div id="-ocd" class="section level2">
<h2>克服 OCD</h2>
<p>对于很多人来说，不可避免地会有这样的强迫症：希望训练误差降至 0。</p>
<p>我们说，人想要过得快乐，首先要接纳自己，与自己和解。做机器学习相关的任务也是一样，首先要理解和接受机器学习的基本规律，克服自己的强迫症。</p>
<p>首先，对于误差，在公式  中，我们得知误差中至少有「随机误差」是无论如何不可避免的。因此，哪怕有一个模型在训练集上的表现非常优秀，它的误差是 0，这也不能说明这个模型完美无缺。因为，训练集本身存在的误差，将会被带入到模型之中；也就是说，这个模型天然地就和真实情况存在误差，于是它不是完美的。</p>
<p>其次，由于训练样本无法完美地反应真实情况（样本容量有限、抽样不均匀），以及由于模型本身的学习能力存在上限，也意味着我们的模型不可能是完美的。</p>
<p>因此，我们需要克服强迫症，不去追求训练误差为 0；转而去追求在给定数据集和模型算法的前提下的，逼近最优结果。</p>
</div>
<div class="section level2">
<h2>最佳平衡点的数学表述</h2>
<p>在实际应用中，我们做模型选择的一般方法是：</p>
<ul>
<li>选定一个算法；</li>
<li>调整算法的超参数；</li>
<li>以某种指标选择最合适的超参数组合。</li>
</ul>
<p>也就是说，在整个过程中，我们固定训练样本，改变模型的描述能力（模型复杂度）。不难理解，随着模型复杂度的增加，其描述能力也就会增加；此时，模型在验证集上的表现，偏差会倾向于减小而方差会倾向于增大。而在相反方向，随着模型复杂度的降低，其描述能力也就会降低；此时，模型在验证集上的表现，偏差会倾向于增大而方差会倾向于减小。</p>
<p>考虑到，模型误差是偏差与方差的加和，因此我们可以绘制出这样的图像。</p>
<div class="figure">
<img src="/images/Data/BiasVariance/bias-variance-tend.png" alt="偏差与误差的变化趋势" />
<p class="caption">偏差与误差的变化趋势</p>
</div>
<p class="imgCaption">
<a href="http://scott.fortmann-roe.com/docs/BiasVariance.html" class="uri">http://scott.fortmann-roe.com/docs/BiasVariance.html</a>
</p>
<p>图中的最有位置，实际上是 total error 曲线的拐点。我们知道，连续函数的拐点意味着此处一阶导数的值为 0。考虑到 total error 是偏差与方差的加和，所以我们有，在拐点处：</p>
<span class="math display">\[\begin{equation}
\newcommand{\dif}{\mathop{}\!\mathrm{d}}
\frac{\dif\text{Bias}}{\dif\text{Complexity}} = - \frac{\dif\text{Variance}}{\dif\text{Complexity}}
\label{eq:sweet}
\end{equation}\]</span>
<p>公式  给出了寻找最优平衡点的数学描述。若模型复杂度大于平衡点，则模型的方差会偏高，模型倾向于过拟合；若模型复杂度小于平衡点，则模型的偏差会偏高，模型倾向于过拟合。</p>
</div>
<div class="section level2">
<h2>过拟合与欠拟合的外在表现</h2>
<p>尽管有了上述数学表述，但是在现实环境中，有时候我们很难计算模型的偏差与方差。因此，我们需要通过外在表现，判断模型的拟合状态：是欠拟合还是过拟合。</p>
<p>同样地，在有限的训练数据集中，不断增加模型的复杂度，意味着模型会尽可能多地降低在训练集上的误差。因此，在训练集上，不断增加模型的复杂度，训练集上的误差会一直下降。</p>
<p>因此，我们可以绘制出这样的图像。</p>
<div class="figure">
<img src="/images/Data/BiasVariance/error-curve.png" alt="训练集和验证集上的误差变化" />
<p class="caption">训练集和验证集上的误差变化</p>
</div>
<p class="imgCaption">
<a href="http://www.learnopencv.com/bias-variance-tradeoff-in-machine-learning/" class="uri">http://www.learnopencv.com/bias-variance-tradeoff-in-machine-learning/</a>
</p>
<p>因此，</p>
<ul>
<li>当模型处于欠拟合状态时，训练集和验证集上的误差都很高；</li>
<li>当模型处于过拟合状态时，训练集上的误差低，而验证集上的误差会非常高。</li>
</ul>
</div>
</div>
<div class="section level1">
<h1>处理欠拟合与过拟合</h1>
<p>有了这些分析，我们就能比较容易地判断模型所处的拟合状态。接下来，我们就可以参考 Andrew Ng 博士提供的处理模型欠拟合/过拟合的一般方法了。</p>
<div class="figure">
<img src="/images/Data/BiasVariance/Machine-Learning-Workflow.png" alt="机器学习调试的一般流程" />
<p class="caption">机器学习调试的一般流程</p>
</div>
<div class="section level2">
<h2>欠拟合</h2>
<p>当模型处于欠拟合状态时，根本的办法是增加模型复杂度。我们一般有以下一些办法：</p>
<ul>
<li>增加模型的迭代次数；</li>
<li>更换描述能力更强的模型；</li>
<li>生成更多特征供训练使用；</li>
<li>降低正则化水平。</li>
</ul>
</div>
<div class="section level2">
<h2>过拟合</h2>
<p>当模型处于过拟合状态时，根本的办法是降低模型复杂度。我们则有以下一些武器：</p>
<ul>
<li>扩增训练集；</li>
<li>减少训练使用的特征的数量；</li>
<li>提高正则化水平。</li>
</ul>
</div>
</div>

    </div>
    

  </article>

  
<section id="comments">
  <div id="disqus_thread"></div>
  <script src="/js/disqusloader.min.js"></script>
  <script>
  var disqus_config = function () {
  
    this.page.url = "https:\/\/haopen.github.io\/" + location.pathname;
  
  };
  (function() {
    var inIFrame = function() {
      var iframe = true;
      try { iframe = window.self !== window.top; } catch (e) {}
      return iframe;
    };
    if (inIFrame()) return;
    var disqus_js = 'https://haopeng.disqus.com/embed.js';
    
    if (location.hash.match(/^#comment/)) {
      var d = document, s = d.createElement('script');
      s.src = disqus_js; s.async = true;
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    } else {
      disqusLoader('#disqus_thread', {
        scriptUrl: disqus_js, laziness: 0, disqusConfig: disqus_config
      });
    }
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>



</main>

      <footer class="footer">
        <ul class="footer-links">
          
          
          <li><a href="https://github.com/haopen"><i class="fa fa-github" aria-hidden="true" title="Github"></i><span class="sr-only">Github</span></a></li>
          <li><a href="https://twitter.com/haopeng"><i class="fa fa-twitter" aria-hidden="true" title="Twitter"></i><span class="sr-only">Twitter</span></a></li>
          <li><a href="http://weibo.com/seplost"><i class="fa fa-weibo" aria-hidden="true" title="新浪微博"></i><span class="sr-only">新浪微博</span></a></li>
          
          <li><a href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><i class="fa fa-cc" aria-hidden="true" title="Attribution-NonCommercial-ShareAlike 4.0 International"></i><span class="sr-only">Attribution-NonCommercial-ShareAlike 4.0 International</span></a></li>
          <li><a href="/"><i class="fa fa-copyright" aria-hidden="true" title="Copyright"></i> 2005 - 2017</a></li>
        </ul>
      </footer>
    </div>

	<div id="images-container"></div>

    <script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
	<script type="text/javascript" src="/lib/jquery/jquery.mousewheel.min.js"></script>
	<script type="text/javascript" src="/lib/lightGallery/js/lightgallery.min.js"></script>
	<script type="text/javascript" src="/lib/lightGallery/js/lg-thumbnail.min.js"></script>
	<script type="text/javascript" src="/lib/lightGallery/js/lg-fullscreen.min.js"></script>
	<script type="text/javascript" src="/lib/lightGallery/js/lg-zoom.min.js"></script>
	<script type="text/javascript" src="/js/lgGallery_Prepare.js"></script>
    
    <script async src="/js/center-img.js"></script>
    
    <script async src="/js/right-quote.js"></script>
    
    <script async src="/js/no-highlight.js"></script>
    
    <script async src="/js/fix-footnote.js"></script>
    
    <script async src="/js/local-search.js"></script>
    
    



<script src="//cdn.bootcss.com/highlight.js/9.11.0/highlight.min.js"></script>



<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/r.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/yaml.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/tex.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/matlab.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true
  }
});
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	TeX: {equationNumbers: {autoNumber: ["AMS"], useLabelIds: true}},
	"HTML-CSS": {linebreaks: {automatic: true}},
	SVG: {linebreaks: {automatic: true}}
});
</script>
<script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

