<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.31" />


<title>Python 爬虫：一些常用的爬虫技巧总结 z - 彭浩 ~ Hao Peng</title>
<meta property="og:title" content="Python 爬虫：一些常用的爬虫技巧总结 z - 彭浩 ~ Hao Peng">



  








<link href='//cdn.bootcss.com/highlight.js/9.11.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">

<link rel="stylesheet" href="/css/custom.css">

<link rel="stylesheet" href="/css/localsearch.css">

<link rel="stylesheet" href="/lib/lightGallery/css/lightgallery.css">

<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script async src="/js/load-typekit.js"></script>



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="Hao Peng">
  </a>

  <ul class="nav-links">
    
	
	
    
	

	
    
    <li class=""><a href="/">首页</a></li>
    
    <li class=""><a href="/tech/">归档</a></li>
    
    <li class=""><a href="/tech/categories/">分类</a></li>
    
    <li class=""><a href="/tech/tags/">标签</a></li>
    
    <li class=""><a href="javascript:;" class="popup-trigger"><i class="fa fa-search" aria-hidden="true" title="搜索"></i></a></li>
    
  </ul>
</nav>


<div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocapitalize="off" autocomplete="off" autocorrect="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>
      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">1793 字</span>
    

    
<h1 class="article-title">Python 爬虫：一些常用的爬虫技巧总结 z


</h1>



<div class="article-date">
  <span> 2016/06/19</span>
  <span class="article-toolbar">
    
    <a href="/tech/index.xml" type="application/rss+xml" target="_blank"><i class="fa fa-rss" aria-hidden="true" title="RSS feed"></i></a>
    
    <a href="https://twitter.com/home?status=Python&#43;%E7%88%AC%E8%99%AB%EF%BC%9A%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E7%9A%84%E7%88%AC%E8%99%AB%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93&#43;z&#43;%2Ftech%2F2016%2F06%2F19%2Fspider%2F&#43;via&#43;%40haopeng" target="_blank"><i class="fa fa-twitter" aria-hidden="true" title="Share via Twitter"></i></a>
    <a href="http://service.weibo.com/share/share.php?content=utf-8&amp;title=Python&#43;%E7%88%AC%E8%99%AB%EF%BC%9A%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E7%9A%84%E7%88%AC%E8%99%AB%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93&#43;z&#43;%40%E5%BD%AD%E6%B5%A9&amp;url=%2Ftech%2F2016%2F06%2F19%2Fspider%2F" target="_blank"><i class="fa fa-weibo" aria-hidden="true" title="分享到新浪微博"></i></a>
    <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><i class="fa fa-cc" aria-hidden="true" title="Attribution-NonCommercial-ShareAlike 4.0 International"></i></a>
    
	
    
	
    <a href="https://github.com/haopen/Blogdown/edit/master/content/tech/2016-06-19-Spider.md"><i class="fa fa-pencil-square-o" aria-hidden="true" title="编辑本页"></i></a>
    
    </span>
</div>

<div class="article-taxonomies">
  
  <span class="category-prefix"><i class="fa fa-folder-o"></i></span>
  
  <span class="taxonomy-category"><a href="/categories/4-python" title="Python">Python</a></span>;
  
  
  
  <span class="tag-prefix"><i class="fa fa-tags"></i></span>
  
  <span class="taxonomy-tag"><a href="/tags/4-python" title="Python&#34;">Python&#34;</a></span>;
  
  <span class="taxonomy-tag"><a href="/tags/4-%E7%88%AC%E8%99%AB" title="爬虫&#34;">爬虫&#34;</a></span>;
  
  
</div>


    
    <div class="article-content cn" id="articleContent">
      

<p><strong>原文地址</strong>：<a href="https://my.oschina.net/jhao104/blog/647308" target="_blank">https://my.oschina.net/jhao104/blog/647308</a></p>

<p>用 Python 也差不多一年多了，Python 应用最多的场景还是 Web 快速开发、爬虫、自动化运维：写过简单网站、写过自动发帖脚本、写过收发邮件脚本、写过简单验证码识别脚本。爬虫在开发过程中也有很多复用的过程，这里总结一下，以后也能省些事情。</p>

<!-- more -->

<h1 id="基本抓取网页">基本抓取网页</h1>

<h2 id="get方法">get方法</h2>

<pre><code class="language-python">import urllib2

url = &quot;http://www.baidu.com&quot;
response = urllib2.urlopen(url)
print response.read()

</code></pre>

<h2 id="post方法">post方法</h2>

<pre><code class="language-python">import urllib
import urllib2

url = &quot;http://abcde.com&quot;
form = {'name':'abc','password':'1234'}
form_data = urllib.urlencode(form)
request = urllib2.Request(url,form_data)
response = urllib2.urlopen(request)
print response.read()
</code></pre>

<h1 id="使用代理-ip">使用代理 IP</h1>

<p>在开发爬虫过程中经常会遇到 IP 被封掉的情况，这时就需要用到代理 IP；在<code>urllib2</code>包中有<code>ProxyHandler</code>类，通过此类可以设置代理访问网页，如下代码片段：</p>

<pre><code class="language-python">import urllib2

proxy = urllib2.ProxyHandler({'http': '127.0.0.1:8087'})
opener = urllib2.build_opener(proxy)
urllib2.install_opener(opener)
response = urllib2.urlopen('http://www.baidu.com')
print response.read()
</code></pre>

<h1 id="cookies处理">Cookies处理</h1>

<p>Cookies 是某些网站为了辨别用户身份、进行 Session 跟踪而储存在用户本地终端上的数据(通常经过加密)，Python 提供了<code>cookielib</code>模块用于处理<code>cookies</code>，<code>cookielib</code>模块的主要作用是提供可存储 cookie 的对象，以便于与<code>urllib2</code>模块配合使用来访问 Internet 资源。</p>

<p>代码片段：</p>

<pre><code class="language-python">import urllib2, cookielib

cookie_support= urllib2.HTTPCookieProcessor(cookielib.CookieJar())
opener = urllib2.build_opener(cookie_support)
urllib2.install_opener(opener)
content = urllib2.urlopen('http://XXXX').read()
</code></pre>

<p>关键在于<code>CookieJar()</code>，它用于管理 HTTP cookie 值、存储 HTTP 请求生成的 cookie、向传出的 HTTP 请求添加 cookie 的对象。整个 cookie 都存储在内存中，对<code>CookieJar</code>实例进行垃圾回收后 cookie 也将丢失，所有过程都不需要单独去操作。</p>

<h2 id="手动添加-cookie">手动添加 cookie</h2>

<pre><code class="language-python">cookie = &quot;PHPSESSID=91rurfqm2329bopnosfu4fvmu7; kmsign=55d2c12c9b1e3; KMUID=b6Ejc1XSwPq9o756AxnBAg=&quot;
request.add_header(&quot;Cookie&quot;, cookie)
</code></pre>

<h1 id="伪装成浏览器">伪装成浏览器</h1>

<p>某些网站反感爬虫的到访，于是对爬虫一律拒绝请求。所以用<code>urllib2</code>直接访问网站经常会出现<code>HTTP Error 403: Forbidden</code>的情况，对有些 header 要特别留意，Server 端会针对这些 header 做检查</p>

<ol>
<li>User-Agent：有些 Server 或 Proxy 会检查该值，用来判断是否是浏览器发起的 Request</li>
<li>Content-Type：在使用 REST 接口时，Server 会检查该值，用来确定 HTTP Body 中的内容该怎样解析。</li>
</ol>

<p>这时可以通过修改<code>http</code>包中的<code>header</code>来实现，代码片段如下：</p>

<pre><code class="language-python">import urllib2

headers = {
    'User-Agent':'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6'
}
request = urllib2.Request(
    url = 'http://my.oschina.net/jhao104/blog?catalog=3463517',
    headers = headers
)
print urllib2.urlopen(request).read()
</code></pre>

<h1 id="页面解析">页面解析</h1>

<p>对于页面解析最强大的当然是正则表达式，这个对于不同网站不同的使用者都不一样，就不用过多的说明，附两个比较好的网址：</p>

<ul>
<li>正则表达式入门：<a href="http://www.cnblogs.com/huxi/archive/2010/07/04/1771073.html" target="_blank">http://www.cnblogs.com/huxi/archive/2010/07/04/1771073.html</a></li>
<li>正则表达式在线测试：<a href="http://tool.oschina.net/regex/" target="_blank">http://tool.oschina.net/regex/</a></li>
</ul>

<p>其次就是解析库了，常用的有两个<code>lxml</code>和<code>BeautifulSoup</code>，对于这两个的使用介绍两个比较好的网站：</p>

<ul>
<li>lxml：<a href="http://my.oschina.net/jhao104/blog/639448" target="_blank">http://my.oschina.net/jhao104/blog/639448</a></li>
<li>BeautifulSoup：<a href="http://cuiqingcai.com/1319.html" target="_blank">http://cuiqingcai.com/1319.html</a></li>
</ul>

<p>对于这两个库，我的评价是，都是 HTML/XML 的处理库，<code>Beautifulsoup</code>纯 Python 实现，效率低，但是功能实用，比如能用通过结果搜索获得某个 HTML 节点的源码；<code>lxml</code>C语言编码，高效，支持<code>Xpath</code>。</p>

<h1 id="验证码的处理">验证码的处理</h1>

<p>对于一些简单的验证码，可以进行简单的识别。本人也只进行过一些简单的验证码识别。但是有些反人类的验证码，比如 12306，可以通过打码平台进行人工打码，当然这是要付费的。</p>

<h1 id="gzip压缩">gzip压缩</h1>

<p>有没有遇到过某些网页，不论怎么转码都是一团乱码。哈哈，那说明你还不知道许多 Web 服务具有发送压缩数据的能力，这可以将网络线路上传输的大量数据消减 60% 以上。这尤其适用于 XML web 服务，因为 XML 数据的压缩率可以很高。</p>

<p>但是一般服务器不会为你发送压缩数据，除非你告诉服务器你可以处理压缩数据。于是需要这样修改代码：</p>

<pre><code class="language-python">import urllib2, httplib
request = urllib2.Request('http://xxxx.com')
request.add_header('Accept-encoding', 'gzip')        1
opener = urllib2.build_opener()
f = opener.open(request)
</code></pre>

<p>这是关键：创建<code>Request</code>对象，添加一个<code>Accept-encoding</code>头信息告诉服务器你能接受 gzip 压缩数据，然后就是解压缩数据：</p>

<pre><code class="language-python">import StringIO
import gzip

compresseddata = f.read() 
compressedstream = StringIO.StringIO(compresseddata)
gzipper = gzip.GzipFile(fileobj=compressedstream) 
print gzipper.read()
</code></pre>

<h1 id="多线程并发抓取">多线程并发抓取</h1>

<p>单线程太慢的话，就需要多线程了，这里给个简单的线程池模板，这个程序只是简单地打印了<code>1-10</code>，但是可以看出是并发的。虽然说 Python 的多线程很鸡肋，但是对于爬虫这种网络频繁型，还是能一定程度提高效率的。</p>

<pre><code class="language-python">from threading import Thread
from Queue import Queue
from time import sleep
# q 是任务队列
# NUM 是并发线程总数
# JOBS 是有多少任务
q = Queue()
NUM = 2
JOBS = 10
# 具体的处理函数，负责处理单个任务
def do_somthing_using(arguments):
    print arguments
# 这个是工作进程，负责不断从队列取数据并处理
def working():
    while True:
        arguments = q.get()
        do_somthing_using(arguments)
        sleep(1)
        q.task_done()
# fork NUM 个线程等待队列
for i in range(NUM):
    t = Thread(target=working)
    t.setDaemon(True)
    t.start()
# 把 JOBS 排入队列
for i in range(JOBS):
    q.put(i)
# 等待所有 JOBS 完成
q.join()
</code></pre>

    </div>
    

<nav id="article-nav">
    
    <a href="/tech/2016/05/22/mro/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title"><i class="fa fa-arrow-circle-left" aria-hidden="true"></i> 你真的理解 Python 中的 MRO 算法吗？z</div>
    </a>
    

    
    <a href="/tech/2016/06/29/introduction-to-remap/" id="article-nav-newer" class="article-nav-link-wrap">
      <div class="article-nav-title">REmap入门示例 z <i class="fa fa-arrow-circle-right" aria-hidden="true"></i></div>
    </a>
    
</nav>
<script type="text/javascript">
document.addEventListener('keyup', function(e) {
  if (e.target.nodeName.toUpperCase() != 'BODY') return;
  var url = false;
  if (e.which == 37) {  
    
    url = '\/tech\/2016\/05\/22\/mro\/';
    
  } else if (e.which == 39) {  
    
    url = '\/tech\/2016\/06\/29\/introduction-to-remap\/';
    
  }
  if (url) window.location = url;
});
</script>



  </article>

  
<section id="comments">
  <div id="disqus_thread"></div>
  <script src="/js/disqusloader.min.js"></script>
  <script>
  var disqus_config = function () {
  
    this.page.url = "https:\/\/haopen.github.io\/" + location.pathname;
  
  };
  (function() {
    var inIFrame = function() {
      var iframe = true;
      try { iframe = window.self !== window.top; } catch (e) {}
      return iframe;
    };
    if (inIFrame()) return;
    var disqus_js = 'https://haopeng.disqus.com/embed.js';
    
    if (location.hash.match(/^#comment/)) {
      var d = document, s = d.createElement('script');
      s.src = disqus_js; s.async = true;
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    } else {
      disqusLoader('#disqus_thread', {
        scriptUrl: disqus_js, laziness: 0, disqusConfig: disqus_config
      });
    }
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>



</main>

      <footer class="footer">
        <ul class="footer-links">
          
          
          <li><a href="https://github.com/haopen"><i class="fa fa-github" aria-hidden="true" title="Github"></i><span class="sr-only">Github</span></a></li>
          <li><a href="https://twitter.com/haopeng"><i class="fa fa-twitter" aria-hidden="true" title="Twitter"></i><span class="sr-only">Twitter</span></a></li>
          <li><a href="http://weibo.com/seplost"><i class="fa fa-weibo" aria-hidden="true" title="新浪微博"></i><span class="sr-only">新浪微博</span></a></li>
          
          <li><a href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><i class="fa fa-cc" aria-hidden="true" title="Attribution-NonCommercial-ShareAlike 4.0 International"></i><span class="sr-only">Attribution-NonCommercial-ShareAlike 4.0 International</span></a></li>
          <li><a href="/"><i class="fa fa-copyright" aria-hidden="true" title="Copyright"></i> 2005 - 2017</a></li>
        </ul>
      </footer>
    </div>

	<div id="images-container"></div>

    <script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
	<script type="text/javascript" src="/lib/jquery/jquery.mousewheel.min.js"></script>
	<script type="text/javascript" src="/lib/lightGallery/js/lightgallery.min.js"></script>
	<script type="text/javascript" src="/lib/lightGallery/js/lg-thumbnail.min.js"></script>
	<script type="text/javascript" src="/lib/lightGallery/js/lg-fullscreen.min.js"></script>
	<script type="text/javascript" src="/lib/lightGallery/js/lg-zoom.min.js"></script>
	<script type="text/javascript" src="/js/lgGallery_Prepare.js"></script>
	<script type="text/javascript" src="/js/load-pangu.js"></script>
    
    <script async src="/js/center-img.js"></script>
    
    <script async src="/js/right-quote.js"></script>
    
    <script async src="/js/no-highlight.js"></script>
    
    <script async src="/js/fix-footnote.js"></script>
    
    <script async src="/js/local-search.js"></script>
    
    



<script src="//cdn.bootcss.com/highlight.js/9.11.0/highlight.min.js"></script>



<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/r.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/yaml.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/tex.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/matlab.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    

    
  </body>
</html>

